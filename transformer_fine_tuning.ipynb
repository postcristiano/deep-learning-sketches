{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22ff507-4feb-472f-a545-caedbbd73584",
   "metadata": {},
   "source": [
    "## Fine-tuning a transformer model for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b4dbee-776d-4cb6-a37b-29b6d74181be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: postcristiano.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"postcristiano.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab049db-bcd6-450d-9780-922a61c47fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60c3bd4-653e-46b6-9799-eeda1ce62538",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc0d26e8-f6b8-4151-b9ed-1c68239dc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project dependencies\n",
    "import os\n",
    "import math\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # OLD | from keras.preprocessing.text import Tokenizer\n",
    "from keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, CallbackList, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam # OLD | from tensorflow.keras.optimizers.experimental import Adam\n",
    "\n",
    "\n",
    "# Disable TensorFlow registration warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Additional configuration to avoid general logging warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "# Ignore specific warningss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d188fb-d46f-4aa6-98ee-3ce83a3928eb",
   "metadata": {},
   "source": [
    "## Load Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47ac02a3-1730-47e6-bef4-de536e8c5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train_data_pt = pd.read_csv('samples/train_data.txt', header = None, delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e23ebbd6-1c72-4f8c-8cce-1613c17baf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_data_pt = pd.read_csv('samples/test_data.txt', header = None, delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dee99937-d2ae-48f9-98aa-65a2568dde7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust columns\n",
    "train_data_pt = train_data_pt.rename(columns = {0: 'raw_text', 1:'sentiment'})\n",
    "test_data_pt = test_data_pt.rename(columns = {0: 'raw_text', 1:'sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a90c716e-6563-489c-8586-96c0de51ac2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "train_data_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b8c645d-cd15-41d7-890f-f2435da52971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "test_data_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29698a9a-1fa6-4195-8ab7-daef0fb6bcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am feeling completely overwhelmed i have two...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have the feeling she was amused and delighted</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was able to help chai lifeline with your sup...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i already feel like i fucked up though because...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i still love my so and wish the best for him i...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text sentiment\n",
       "0  i am feeling completely overwhelmed i have two...      fear\n",
       "1    i have the feeling she was amused and delighted       joy\n",
       "2  i was able to help chai lifeline with your sup...       joy\n",
       "3  i already feel like i fucked up though because...     anger\n",
       "4  i still love my so and wish the best for him i...   sadness"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data train sample\n",
    "train_data_pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9ea662a-04ae-4184-8258-80116d3f7260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List sentiments in data train\n",
    "train_data_pt['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0973d2c-ebf6-4089-a05b-14167cacd560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "joy         695\n",
       "sadness     581\n",
       "anger       275\n",
       "fear        224\n",
       "love        159\n",
       "surprise     66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List sentiments in data test\n",
    "test_data_pt['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23750205-a2c3-454d-b976-2e307b33db6d",
   "metadata": {},
   "source": [
    "## Pre-processing of Text Data with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b059206-5132-4bb4-83f0-5a7205e4335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe184ca3-c716-46f9-90f1-e4dbb2a7cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary\n",
    "pt_nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4848c1a0-3411-4a15-9784-568284b12fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set function 'pt_preprocessing_text' that receives a text as a parameter\n",
    "def pt_preprocessing_text(text):\n",
    "    \n",
    "    # Process the text using the dictionary\n",
    "    doc = pt_nlp(text)\n",
    "    \n",
    "    # Creates a list of lemmas from the tokens, converted to lowercase and without blanks, \n",
    "    # excluding words that are stopwords\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop]\n",
    "    \n",
    "    # returns the processed tokens as a single string, joining them with spaces\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1368a862-83a8-471e-a540-d32a2f08010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies function in train data\n",
    "train_data_pt['processed_text'] = train_data_pt['raw_text'].apply(pt_preprocessing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7e7df51-df76-4d78-8718-ceb7e5d29de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies function in test data\n",
    "test_data_pt['processed_text'] = test_data_pt['raw_text'].apply(pt_preprocessing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b7a0c6d-4c5d-4948-9cc0-d774b910c0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel like my only role now would be to tear ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>feel like role tear sail pessimism discontent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel just bcoz a fight we get mad to each ot...</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel bcoz fight mad n u wanna publicity n let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like reds and purples are just so rich ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>feel like red purple rich kind perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im not sure the feeling of loss will ever go a...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>m sure feeling loss away dull sweet feeling no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel like ive gotten to know many of you thr...</td>\n",
       "      <td>joy</td>\n",
       "      <td>feel like ve get know comment email m apprecia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text sentiment  \\\n",
       "0  i feel like my only role now would be to tear ...   sadness   \n",
       "1  i feel just bcoz a fight we get mad to each ot...     anger   \n",
       "2  i feel like reds and purples are just so rich ...       joy   \n",
       "3  im not sure the feeling of loss will ever go a...   sadness   \n",
       "4  i feel like ive gotten to know many of you thr...       joy   \n",
       "\n",
       "                                      processed_text  \n",
       "0      feel like role tear sail pessimism discontent  \n",
       "1  feel bcoz fight mad n u wanna publicity n let ...  \n",
       "2             feel like red purple rich kind perfect  \n",
       "3  m sure feeling loss away dull sweet feeling no...  \n",
       "4  feel like ve get know comment email m apprecia...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data train sample\n",
    "test_data_pt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef36d99-09da-4593-bea7-ad3ce983eb13",
   "metadata": {},
   "source": [
    "## Model 1 - Fully Connected Neural Network Architecture\n",
    "\n",
    "### *Step 1 | Vectorization with TF-IDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c42e052-35e8-48bc-a4ba-50f9b00c2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer\n",
    "pt_tfidf = TfidfVectorizer(max_df = 0.95, min_df = 2, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556590a-cdf0-493d-bd4b-e9e5b4c97f73",
   "metadata": {},
   "source": [
    "Above creates an instance of TfidfVectorizer from the scikit-learn library, which is a tool used to convert a collection of raw documents into a TF-IDF (Term Frequency-Inverse Document Frequency) feature matrix. TF-IDF is a statistical technique used to quantify the importance of a word in a set of documents, commonly used in natural language processing and information retrieval tasks.\n",
    "\n",
    "**Parameter max_df=0.95:** This parameter defines the maximum document frequency limit for the terms that will be considered. Here, it is set to 0.95, which means that words that appear in more than 95% of documents will be ignored. This helps eliminate common words that don't contribute much to the meaning of the text.\n",
    "\n",
    "**Parameter min_df=2:** This parameter establishes the minimum document frequency for the terms. In this case, terms that appear in less than 2 documents will be ignored. This helps filter out rare terms that may only occur in a few samples and are therefore less relevant to the overall analysis.\n",
    "\n",
    "**stop_words='english'**: This parameter instructs the vectorizer to remove all English stop words from the analysis. Stop words are common words (such as \"and\", \"the\", \"in\") that are often filtered out in natural language processing because they are too frequent and do not carry meaningful information for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5faef90-372b-4990-83f9-791220f74eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies vectorizer\n",
    "# fit_transform only train data sample, because fit_transform is a train procedure.\n",
    "train_data_tfidf = pt_tfidf.fit_transform(train_data_pt['processed_text']) \n",
    "\n",
    "test_data_tfidf = pt_tfidf.transform(test_data_pt['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c2bacdc-3dfe-4d23-8bc2-ebb56c5abd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 5587)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ef972b6-7bb4-4035-a8d7-f454ed102320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c95b37b8-9c49-490a-807f-debe53d62900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input data (processed text) to array\n",
    "X_train_array = train_data_tfidf.toarray()\n",
    "X_test_array = test_data_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5aa89c-347f-4833-aca8-ecded18c49a8",
   "metadata": {},
   "source": [
    "### Step 2: Data Preparation\n",
    "\n",
    "We now need to convert the target variable to numeric representation. We will use Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eb68423-c9d8-425a-834b-829fe31f3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Label Encoder\n",
    "pt_le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a963dc39-124a-4f58-be27-74f02c5820ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the target variable in train\n",
    "y_train_le = pt_le.fit_transform(train_data_pt['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0e1caee-f8ef-4af4-9c62-aab60b2d8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the target variable in test\n",
    "y_test_le = pt_le.transform(test_data_pt['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e24a6ff-8887-4c21-b857-9165ab5c05a8",
   "metadata": {},
   "source": [
    "**We will automatically handle class imbalance.**\n",
    "\n",
    "**Techniques for balancing the data sample**\n",
    "- Oversampling: Creation of synthetic data and increases the number of records\n",
    "- Undersamplimeng: Decreases records of major classes, results in data loss\n",
    "- Give more weight in training to classes with smaller sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d52b07a3-4d41-412b-a28a-875d93586655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights\n",
    "classes_weights = compute_class_weight('balanced', classes = np.unique(y_train_le), y = y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f08b1218-d58c-4ab1-9247-21e622ac4773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classes_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d307f81-c53d-4fc9-9ff9-d194c05bb0a6",
   "metadata": {},
   "source": [
    "**compute_class_weight**: This is a scikit-learn function that calculates weights for classes. These weights can be used in classification models to give more importance to classes that are underrepresented in the dataset.\n",
    "\n",
    "**'balanced'**: This parameter indicates that the weights of the classes must be calculated in such a way that they balance the data set. This is done inversely proportional to the frequency of classes in the data set. More frequent classes receive a lower weight, while less frequent classes receive a greater weight.\n",
    "\n",
    "**classes** = np.unique(y_treino_le): Here, np.unique(y_treino_le) finds all the unique classes in the training dataset. The classes parameter tells the compute_class_weight function what these unique classes are.\n",
    "\n",
    "**y = y_train_le**: This is the label vector of the training dataset. The function will use these labels to calculate the frequency of each class.\n",
    "\n",
    "The result, stored in pesos_classes, is an array where each class has an associated weight. These weights can be used in classification models (such as a decision tree, a logistic regression model, SVM, etc.) to compensate for imbalance between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b298f8a-2554-438a-a844-591c9ec55b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division into Train Data and Test Data (Test to VALIDATION)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_array,\n",
    "                                                  y_train_le,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state = 42,\n",
    "                                                  stratify = y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef3f1d8c-bb5c-483d-94bc-c8c4300f944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target variable as categorical type\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test_le)\n",
    "y_val_encoded = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd842d3a-fc24-4ebf-9dd9-6629a5d89366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12800, 6), (2000, 6), (3200, 6))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape \n",
    "y_train_encoded.shape, y_test_encoded.shape, y_val_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8515b5cc-2635-4355-8325-4f8730541c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: postcristiano.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"postcristiano.pt\"\n",
    "\n",
    "#%watermark -v -m\n",
    "\n",
    "#%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38653435-5440-419a-b2f2-d484a3f2eab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
